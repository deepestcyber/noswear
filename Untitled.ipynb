{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DeepSpeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepSpeech.load_model('models/librispeech_pretrained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSpeech(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "    (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "  )\n",
       "  (rnns): Sequential(\n",
       "    (0): BatchRNN(\n",
       "      (rnn): GRU(672, 800, bias=False, bidirectional=True)\n",
       "    )\n",
       "    (1): BatchRNN(\n",
       "      (batch_norm): SequenceWise (\n",
       "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
       "    )\n",
       "    (2): BatchRNN(\n",
       "      (batch_norm): SequenceWise (\n",
       "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
       "    )\n",
       "    (3): BatchRNN(\n",
       "      (batch_norm): SequenceWise (\n",
       "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
       "    )\n",
       "    (4): BatchRNN(\n",
       "      (batch_norm): SequenceWise (\n",
       "      BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (rnn): GRU(800, 800, bias=False, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): SequenceWise (\n",
       "    Sequential(\n",
       "      (0): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Linear(in_features=800, out_features=29, bias=False)\n",
       "    ))\n",
       "  )\n",
       "  (inference_softmax): InferenceBatchSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rnns = torch.nn.GRU(672, 10, bias=False)\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(10, 1),\n",
    ")\n",
    "model.inference_softmax = torch.nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSpeech(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "    (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "  )\n",
       "  (rnns): GRU(672, 10, bias=False)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       "  (inference_softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e24d18056e0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectrogramParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/deepcyber/DeepSpeech.pytorch/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/deepcyber/DeepSpeech.pytorch/data/data_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchaudio'"
     ]
    }
   ],
   "source": [
    "from data.data_loader import SpectrogramParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwearDataset:\n",
    "    def __init__(self, good_word_path, bad_word_path):\n",
    "        self.good_word_path = good_word_path\n",
    "        self.bad_word_path = bad_word_path\n",
    "        \n",
    "    def words_from_file(self, path):\n",
    "        with open(path) as f:\n",
    "            for line in f:\n",
    "                if not line.strip() or line.startswith('#'):\n",
    "                    continue\n",
    "                yield line.strip()\n",
    "    \n",
    "    def load(self):\n",
    "        good_words = self.words_from_file(self.good_word_path)\n",
    "        bad_words = self.words_from_file(self.bad_word_path)\n",
    "        \n",
    "        \n",
    "        return list(good_words), list(bad_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SwearDataset(\n",
    "    good_word_path='../crawler/good_words.txt',\n",
    "    bad_word_path='../crawler/bad_words.txt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['duck',\n",
       "  'fit',\n",
       "  'misfit',\n",
       "  'grunt',\n",
       "  'person',\n",
       "  'chicken',\n",
       "  'what',\n",
       "  'he',\n",
       "  'she',\n",
       "  'it',\n",
       "  'when'],\n",
       " ['shit', 'fuck', 'cunt', 'asshole', 'ass', 'fucktard', 'piss'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechNet(skorch.NeuralNet):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SpeechNet(model, \n",
    "    criterion=torch.nn.NLLLoss,\n",
    "    callbacks=[\n",
    "        skorch.callbacks.Freezer(lambda n: not n.startswith('rnns') and not n.startswith('fc')),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
