{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import skorch\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemo/envs/noswear/lib/python3.6/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "from deepspeech.model import DeepSpeech\n",
    "from deepspeech.model import SequenceWise\n",
    "from deepspeech.data.data_loader import SpectrogramParser\n",
    "from deepspeech.data.data_loader import BucketingSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import dataset\n",
    "from utils import RNNValueExtractor\n",
    "from utils import Identity\n",
    "from utils import bucketing_dataloader\n",
    "from utils import filter_low_count_words\n",
    "from layers import ResidualRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = DeepSpeech.load_model(\n",
    "    'models/librispeech_pretrained.pth'\n",
    ")\n",
    "audio_conf = DeepSpeech.get_audio_conf(base_model)\n",
    "parser = SpectrogramParser(audio_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_swear = dataset.SwearDataset(dataset.DEFAULT_PROVIDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_swear, y_swear = ds_swear.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = dataset.SwearBinaryAudioDataset(X_swear, y_swear, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemo/envs/noswear/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=320 is too small for input signal of length=1\n",
      "  n_fft, y.shape[-1]\n",
      "/home/nemo/envs/noswear/lib/python3.6/site-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=320 is too small for input signal of length=2\n",
      "  n_fft, y.shape[-1]\n"
     ]
    }
   ],
   "source": [
    "X, y = ds.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161, 161.0, 161.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lens = np.array([x.shape[0] for x in X])\n",
    "max_seq_len = max(seq_lens)\n",
    "max_seq_len, np.mean(seq_lens), np.median(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad = np.zeros(\n",
    "    (len(X), X[0].shape[0], max_seq_len), \n",
    "    dtype='float32'\n",
    ")\n",
    "for i, _ in enumerate(X):\n",
    "    X_pad[i, :, :seq_lens[i]] = X[i]\n",
    "    \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter low count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = filter_low_count_words(X_swear, min_count=4)\n",
    "X_pad = X_pad[idcs]\n",
    "y = y[idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemo/envs/noswear/lib/python3.6/site-packages/scikit_learn-0.23.2-py3.6-linux-x86_64.egg/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# use word as class for stratified split to make sure that train/test\n",
    "# set both contain examples of the all words.\n",
    "y_word = np.array([n[0] for n in X_swear])[idcs]\n",
    "train_idcs_proto, test_idcs = next(split.split(y, y=y_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemo/envs/noswear/lib/python3.6/site-packages/scikit_learn-0.23.2-py3.6-linux-x86_64.egg/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_idcs, valid_idcs = next(split.split(y[train_idcs_proto], y=y_word[train_idcs_proto]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idcs = train_idcs_proto[train_idcs]\n",
    "valid_idcs = train_idcs_proto[valid_idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(311)\n",
    "plt.title('\"class\" balance between train/test\\ntrain')\n",
    "plt.hist(y_word[train_idcs]);\n",
    "plt.subplot(312)\n",
    "plt.title('valid')\n",
    "plt.hist(y_word[valid_idcs]);\n",
    "plt.subplot(313)\n",
    "plt.title('test')\n",
    "plt.hist(y_word[test_idcs]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = {'lens': seq_lens[train_idcs], 'X': X_pad[train_idcs]}\n",
    "y_train = np.array(y)[train_idcs]\n",
    "\n",
    "X_valid = {'lens': seq_lens[valid_idcs], 'X': X_pad[valid_idcs]}\n",
    "y_valid = np.array(y)[valid_idcs]\n",
    "\n",
    "X_test = {'lens': seq_lens[test_idcs], 'X': X_pad[test_idcs]}\n",
    "y_test = np.array(y)[test_idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 34, 42)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train['X']), len(X_valid['X']), len(X_test['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoSwearModel(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        base_model, \n",
    "        n_hidden=10, \n",
    "        n_layer=1,\n",
    "        p_dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.base_model.rnns = Identity()\n",
    "        self.base_model.lookahead = Identity()\n",
    "        self.base_model.fc = Identity()\n",
    "        self.base_model.inference_softmax = Identity()\n",
    "        \n",
    "        self.rnn = torch.nn.Sequential(\n",
    "            torch.nn.GRU(672, n_hidden, num_layers=n_layer, bias=False, batch_first=True),\n",
    "            RNNValueExtractor(),\n",
    "        )\n",
    "\n",
    "        self.clf = torch.nn.Linear(n_hidden, 2, bias=False)\n",
    "        self.dropout = torch.nn.Dropout(p=p_dropout)\n",
    "        \n",
    "    def forward(self, X, lens):\n",
    "        # run base model, output is NxTxH with\n",
    "        # T=Time, N=samples, H=hidden.\n",
    "        y_pre = self.base_model(X)\n",
    "        y_pre = self.dropout(y_pre)\n",
    "        \n",
    "        # run RNN over sequence and extract last item\n",
    "        y = self.rnn(y_pre)\n",
    "        # presumably we cannot use lens since cnns reduce that too\n",
    "        #y = y[:, lens - 1]\n",
    "        #y = y[:, -1]\n",
    "        i = y.mean(-1).argmax(1)\n",
    "        y = y[torch.arange(len(y)), i]\n",
    "        \n",
    "        y = self.dropout(y)\n",
    "        \n",
    "        # run classifier\n",
    "        y = self.clf(y)\n",
    "        y = torch.softmax(y, dim=-1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket(Xi, yi):\n",
    "    Xi['X'] = Xi['X'][:, :, :max(Xi['lens'])]\n",
    "    return Xi, yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "net = skorch.classifier.NeuralNetClassifier(\n",
    "    partial(NoSwearModel, base_model), \n",
    "    \n",
    "    iterator_train=bucketing_dataloader,\n",
    "    iterator_train__bucket_fn=bucket,\n",
    "    iterator_valid=bucketing_dataloader,\n",
    "    iterator_valid__bucket_fn=bucket,\n",
    "    \n",
    "    batch_size=8,\n",
    "    max_epochs=40,\n",
    "    device='cuda',\n",
    "    \n",
    "    train_split=predefined_split(Dataset(X_valid, y_valid)),\n",
    "    \n",
    "    module__p_dropout=0.2,\n",
    "    module__n_hidden=16,\n",
    "        \n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=0.02,\n",
    "    \n",
    "    callbacks=[\n",
    "        skorch.callbacks.Freezer('base_model.*'),\n",
    "        #skorch.callbacks.Checkpoint(monitor='valid_acc_best'),\n",
    "        #skorch.callbacks.TrainEndCheckpoint(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected module output to have shape (n,) or (n, 1), got (8, 2) instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-6a987aaf8c12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pdb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'on'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# this is actually a pylint bug:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             self.run_single_epoch(dataset_train, training=True, prefix=\"train\",\n\u001b[0;32m--> 776\u001b[0;31m                                   step_fn=self.train_step, **fit_params)\n\u001b[0m\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdataset_valid\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mrun_single_epoch\u001b[0;34m(self, dataset, training, prefix, step_fn, **fit_params)\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0myi_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myi\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_placeholder_y\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_begin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myi_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_batch_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/noswear/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envs/noswear/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mstep_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0mstep_accumulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/net.py\u001b[0m in \u001b[0;36mtrain_step_single\u001b[0;34m(self, Xi, yi, **fit_params)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \"\"\"\n\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/pytorch/skorch/skorch/classifier.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, x, **fit_params)\u001b[0m\n\u001b[1;32m    303\u001b[0m             raise ValueError(\n\u001b[1;32m    304\u001b[0m                 \u001b[0;34m\"Expected module output to have shape (n,) or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \"(n, 1), got {} instead\".format(tuple(y_infer.shape)))\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0my_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_infer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected module output to have shape (n,) or (n, 1), got (8, 2) instead"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/nemo/Code/pytorch/skorch/skorch/classifier.py\u001b[0m(305)\u001b[0;36minfer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    303 \u001b[0;31m            raise ValueError(\n",
      "\u001b[0m\u001b[0;32m    304 \u001b[0;31m                \u001b[0;34m\"Expected module output to have shape (n,) or \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 305 \u001b[0;31m                \"(n, 1), got {} instead\".format(tuple(y_infer.shape)))\n",
      "\u001b[0m\u001b[0;32m    306 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    307 \u001b[0;31m        \u001b[0my_infer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_infer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%pdb on\n",
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n",
      "  epoch    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  ------------  -----------  ------------  ----  ------\n",
      "      1        \u001b[36m0.9890\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7355\u001b[0m     +  0.2529\n",
      "      2        \u001b[36m0.7623\u001b[0m       \u001b[32m0.5263\u001b[0m        \u001b[35m0.7023\u001b[0m     +  0.2549\n",
      "      3        \u001b[36m0.6927\u001b[0m       0.5263        0.7195        0.2552\n",
      "      4        \u001b[36m0.6722\u001b[0m       0.5000        0.7645        0.2544\n",
      "      5        0.7062       0.5000        0.7878        0.2545\n",
      "      6        0.6926       0.5000        0.7748        0.2544\n",
      "      7        0.6867       \u001b[32m0.5526\u001b[0m        0.7576     +  0.2532\n",
      "      8        0.7088       \u001b[32m0.6053\u001b[0m        0.7238     +  0.2532\n",
      "      9        0.7010       0.6053        \u001b[35m0.6981\u001b[0m        0.2520\n",
      "     10        \u001b[36m0.6377\u001b[0m       0.6053        \u001b[35m0.6762\u001b[0m        0.2544\n",
      "     11        0.6497       \u001b[32m0.6579\u001b[0m        \u001b[35m0.6661\u001b[0m     +  0.2544\n",
      "     12        \u001b[36m0.6116\u001b[0m       \u001b[32m0.6842\u001b[0m        \u001b[35m0.6583\u001b[0m     +  0.2566\n",
      "     13        0.6287       0.6579        0.6600        0.2538\n",
      "     14        0.6146       0.6842        \u001b[35m0.6498\u001b[0m        0.2566\n",
      "     15        \u001b[36m0.6050\u001b[0m       \u001b[32m0.7368\u001b[0m        \u001b[35m0.6474\u001b[0m     +  0.2547\n",
      "     16        \u001b[36m0.6039\u001b[0m       0.7368        \u001b[35m0.6413\u001b[0m        0.2547\n",
      "     17        \u001b[36m0.5903\u001b[0m       0.7105        \u001b[35m0.6262\u001b[0m        0.2576\n",
      "     18        0.6008       0.7105        0.6371        0.2554\n",
      "     19        \u001b[36m0.5825\u001b[0m       0.7105        0.6280        0.2570\n",
      "     20        0.5860       0.6316        0.6294        0.2568\n",
      "     21        \u001b[36m0.5652\u001b[0m       0.6316        \u001b[35m0.6245\u001b[0m        0.2555\n",
      "     22        0.5791       0.6316        \u001b[35m0.6210\u001b[0m        0.2552\n",
      "     23        \u001b[36m0.5503\u001b[0m       0.6316        \u001b[35m0.6172\u001b[0m        0.2571\n",
      "     24        \u001b[36m0.5421\u001b[0m       0.6316        \u001b[35m0.6117\u001b[0m        0.2583\n",
      "     25        \u001b[36m0.5076\u001b[0m       0.6316        \u001b[35m0.6074\u001b[0m        0.2577\n",
      "     26        0.5174       0.6316        \u001b[35m0.6019\u001b[0m        0.2571\n",
      "     27        \u001b[36m0.4986\u001b[0m       0.6316        0.6103        0.2572\n",
      "     28        \u001b[36m0.4809\u001b[0m       0.6316        0.6087        0.2566\n",
      "     29        0.4896       0.6053        0.6082        0.2570\n",
      "     30        \u001b[36m0.4793\u001b[0m       0.6053        0.6044        0.2567\n",
      "     31        \u001b[36m0.4193\u001b[0m       0.6579        0.6025        0.2555\n",
      "     32        0.4775       0.6842        \u001b[35m0.5956\u001b[0m        0.2577\n",
      "     33        \u001b[36m0.4169\u001b[0m       0.7105        0.6017        0.2572\n",
      "     34        0.4813       0.7368        \u001b[35m0.5388\u001b[0m        0.2568\n",
      "     35        \u001b[36m0.4067\u001b[0m       0.7368        \u001b[35m0.5317\u001b[0m        0.2565\n",
      "     36        0.4577       0.7105        \u001b[35m0.4955\u001b[0m        0.2550\n",
      "     37        \u001b[36m0.3511\u001b[0m       \u001b[32m0.7632\u001b[0m        \u001b[35m0.4950\u001b[0m     +  0.2545\n",
      "     38        0.3829       0.7368        \u001b[35m0.4917\u001b[0m        0.2588\n",
      "     39        0.3883       0.7368        \u001b[35m0.4683\u001b[0m        0.2583\n",
      "     40        0.3637       0.7368        \u001b[35m0.4635\u001b[0m        0.2578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=NoSwearModel(\n",
       "    (base_model): DeepSpeech(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "        (3): Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1))\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): Hardtanh(min_val=0, max_val=20, inplace)\n",
       "      )\n",
       "      (rnns): Identity()\n",
       "      (fc): Identity()\n",
       "      (inference_softmax): Identity()\n",
       "      (lookahead): Identity()\n",
       "    )\n",
       "    (rnn): Sequential(\n",
       "      (0): GRU(672, 300, bias=False, batch_first=True)\n",
       "      (1): RNNValueExtractor()\n",
       "    )\n",
       "    (clf): Linear(in_features=300, out_features=2, bias=False)\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pdb on\n",
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.load_params(checkpoint=dict(net.callbacks_)['Checkpoint'])\n",
    "#net.load_params(checkpoint=dict(net.callbacks_)['TrainEndCheckpoint'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, net.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch.helper import SliceDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.initialize();\n",
    "net.set_params(verbose=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'optimizer__lr': [0.02, 0.002, 0.0002],\n",
    "    'optimizer__weight_decay': [0, 1e-4],\n",
    "    'optimizer': [torch.optim.RMSprop, torch.optim.Adam],\n",
    "    'module__p_dropout': [0, 0.5],\n",
    "    'module__n_hidden': [10, 100, 200, 400],\n",
    "    'module__n_layer': [1, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(net, params, scoring='accuracy', cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "gs.fit(SliceDict(**X_train), y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=functools.partial(<class '__main__.NoSwearModel'>, DeepSpeech(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(0, 10))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1,...ax): Identity()\n",
       "    (lookahead): Identity()\n",
       "  )),\n",
       "  module__n_hidden=300,\n",
       "  module__p_dropout=0.2,\n",
       "),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'optimizer__lr': [0.02, 0.002, 0.0002], 'module__n_layer': [1, 2], 'optimizer': [<class 'torch.optim.rmsprop.RMSprop'>, <class 'torch.optim.adam.Adam'>], 'optimizer__weight_decay': [0, 0.0001], 'module__n_hidden': [10, 100, 200, 400], 'module__p_dropout': [0, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_results = results.sort_values(by='mean_test_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_module__n_hidden</th>\n",
       "      <th>param_module__n_layer</th>\n",
       "      <th>param_module__p_dropout</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>param_optimizer__lr</th>\n",
       "      <th>param_optimizer__weight_decay</th>\n",
       "      <th>...</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>22.166183</td>\n",
       "      <td>0.159822</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.339894</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.206958</td>\n",
       "      <td>0.120451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>16.474293</td>\n",
       "      <td>0.131874</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.898374</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.414634</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.112958</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.173991</td>\n",
       "      <td>0.075395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>18.050158</td>\n",
       "      <td>0.131793</td>\n",
       "      <td>0.203252</td>\n",
       "      <td>0.922764</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>0.266049</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.135556</td>\n",
       "      <td>0.058344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.388777</td>\n",
       "      <td>0.089013</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.703252</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>1.072718</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>0.154365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>29.559384</td>\n",
       "      <td>0.185374</td>\n",
       "      <td>0.211382</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>400</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.560976</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957089</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.248998</td>\n",
       "      <td>0.094986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>17.208370</td>\n",
       "      <td>0.147030</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.861789</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.424042</td>\n",
       "      <td>0.016235</td>\n",
       "      <td>0.202111</td>\n",
       "      <td>0.092519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>18.502019</td>\n",
       "      <td>0.154078</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.512195</td>\n",
       "      <td>0.914634</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.414292</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>0.207914</td>\n",
       "      <td>0.044900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>16.482110</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.695122</td>\n",
       "      <td>0.092012</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.192049</td>\n",
       "      <td>0.133715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>17.353589</td>\n",
       "      <td>0.131291</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.930894</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.792683</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599841</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>0.163008</td>\n",
       "      <td>0.097730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.399436</td>\n",
       "      <td>0.129530</td>\n",
       "      <td>0.227642</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;class 'torch.optim.rmsprop.RMSprop'&gt;</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024390</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167875</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.043403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "144      22.166183         0.159822         0.146341          0.666667   \n",
       "56       16.474293         0.131874         0.178862          0.898374   \n",
       "97       18.050158         0.131793         0.203252          0.922764   \n",
       "12       10.388777         0.089013         0.211382          0.703252   \n",
       "189      29.559384         0.185374         0.211382          0.865854   \n",
       "63       17.208370         0.147030         0.219512          0.861789   \n",
       "101      18.502019         0.154078         0.219512          0.918699   \n",
       "55       16.482110         0.139156         0.219512          0.813008   \n",
       "79       17.353589         0.131291         0.219512          0.930894   \n",
       "26       16.399436         0.129530         0.227642          0.963415   \n",
       "\n",
       "    param_module__n_hidden param_module__n_layer param_module__p_dropout  \\\n",
       "144                    400                     1                       0   \n",
       "56                     100                     1                       0   \n",
       "97                     200                     1                       0   \n",
       "12                      10                     1                     0.5   \n",
       "189                    400                     2                     0.5   \n",
       "63                     100                     1                     0.5   \n",
       "101                    200                     1                       0   \n",
       "55                     100                     1                       0   \n",
       "79                     100                     2                       0   \n",
       "26                      10                     2                       0   \n",
       "\n",
       "                           param_optimizer param_optimizer__lr  \\\n",
       "144  <class 'torch.optim.rmsprop.RMSprop'>                0.02   \n",
       "56         <class 'torch.optim.adam.Adam'>               0.002   \n",
       "97   <class 'torch.optim.rmsprop.RMSprop'>                0.02   \n",
       "12   <class 'torch.optim.rmsprop.RMSprop'>                0.02   \n",
       "189        <class 'torch.optim.adam.Adam'>               0.002   \n",
       "63   <class 'torch.optim.rmsprop.RMSprop'>               0.002   \n",
       "101  <class 'torch.optim.rmsprop.RMSprop'>              0.0002   \n",
       "55         <class 'torch.optim.adam.Adam'>                0.02   \n",
       "79         <class 'torch.optim.adam.Adam'>                0.02   \n",
       "26   <class 'torch.optim.rmsprop.RMSprop'>               0.002   \n",
       "\n",
       "    param_optimizer__weight_decay       ...        split0_test_score  \\\n",
       "144                             0       ...                 0.000000   \n",
       "56                              0       ...                 0.000000   \n",
       "97                         0.0001       ...                 0.073171   \n",
       "12                              0       ...                 0.000000   \n",
       "189                        0.0001       ...                 0.000000   \n",
       "63                         0.0001       ...                 0.000000   \n",
       "101                        0.0001       ...                 0.097561   \n",
       "55                         0.0001       ...                 0.121951   \n",
       "79                         0.0001       ...                 0.048780   \n",
       "26                              0       ...                 0.024390   \n",
       "\n",
       "     split0_train_score  split1_test_score  split1_train_score  \\\n",
       "144            0.780488           0.439024            0.500000   \n",
       "56             0.792683           0.414634            0.939024   \n",
       "97             0.975610           0.390244            0.841463   \n",
       "12             0.780488           0.536585            0.487805   \n",
       "189            0.792683           0.560976            0.804878   \n",
       "63             0.829268           0.487805            0.768293   \n",
       "101            0.975610           0.512195            0.914634   \n",
       "55             1.000000           0.487805            0.743902   \n",
       "79             0.792683           0.439024            1.000000   \n",
       "26             0.987805           0.390244            0.902439   \n",
       "\n",
       "     split2_test_score  split2_train_score  std_fit_time  std_score_time  \\\n",
       "144           0.000000            0.719512      0.339894        0.017730   \n",
       "56            0.121951            0.963415      0.112958        0.008257   \n",
       "97            0.146341            0.951220      0.266049        0.002605   \n",
       "12            0.097561            0.841463      1.072718        0.012990   \n",
       "189           0.073171            1.000000      0.957089        0.010750   \n",
       "63            0.170732            0.987805      0.424042        0.016235   \n",
       "101           0.048780            0.865854      0.414292        0.008792   \n",
       "55            0.048780            0.695122      0.092012        0.011236   \n",
       "79            0.170732            1.000000      0.599841        0.003257   \n",
       "26            0.268293            1.000000      0.167875        0.000289   \n",
       "\n",
       "     std_test_score  std_train_score  \n",
       "144        0.206958         0.120451  \n",
       "56         0.173991         0.075395  \n",
       "97         0.135556         0.058344  \n",
       "12         0.233377         0.154365  \n",
       "189        0.248998         0.094986  \n",
       "63         0.202111         0.092519  \n",
       "101        0.207914         0.044900  \n",
       "55         0.192049         0.133715  \n",
       "79         0.163008         0.097730  \n",
       "26         0.152100         0.043403  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144    {'optimizer__lr': 0.02, 'module__n_layer': 1, ...\n",
       "56     {'optimizer__lr': 0.002, 'module__n_layer': 1,...\n",
       "97     {'optimizer__lr': 0.02, 'module__n_layer': 1, ...\n",
       "12     {'optimizer__lr': 0.02, 'module__n_layer': 1, ...\n",
       "189    {'optimizer__lr': 0.002, 'module__n_layer': 2,...\n",
       "63     {'optimizer__lr': 0.002, 'module__n_layer': 1,...\n",
       "101    {'optimizer__lr': 0.0002, 'module__n_layer': 1...\n",
       "55     {'optimizer__lr': 0.02, 'module__n_layer': 1, ...\n",
       "79     {'optimizer__lr': 0.02, 'module__n_layer': 2, ...\n",
       "26     {'optimizer__lr': 0.002, 'module__n_layer': 2,...\n",
       "Name: params, dtype: object"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.set_params(verbose=True, **top_results.params.iloc[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.1913\u001b[0m       \u001b[32m0.5263\u001b[0m        \u001b[35m0.7722\u001b[0m  0.2194\n",
      "      2        \u001b[36m0.7487\u001b[0m       0.5000        \u001b[35m0.7050\u001b[0m  0.2168\n",
      "      3        \u001b[36m0.6382\u001b[0m       0.4737        0.7146  0.2119\n",
      "      4        0.6410       0.4737        0.7574  0.2147\n",
      "      5        0.6705       0.4737        0.7788  0.2137\n",
      "      6        0.6884       0.4737        0.7601  0.2145\n",
      "      7        0.6753       0.4474        0.7377  0.2140\n",
      "      8        0.6573       0.4474        0.7066  0.2130\n",
      "      9        \u001b[36m0.6326\u001b[0m       0.5000        \u001b[35m0.6925\u001b[0m  0.2161\n",
      "     10        \u001b[36m0.6150\u001b[0m       0.5000        \u001b[35m0.6870\u001b[0m  0.2150\n",
      "     11        \u001b[36m0.6107\u001b[0m       \u001b[32m0.6053\u001b[0m        \u001b[35m0.6543\u001b[0m  0.2144\n",
      "     12        \u001b[36m0.6004\u001b[0m       0.6053        \u001b[35m0.6482\u001b[0m  0.2159\n",
      "     13        \u001b[36m0.5902\u001b[0m       \u001b[32m0.6316\u001b[0m        \u001b[35m0.6414\u001b[0m  0.2104\n",
      "     14        \u001b[36m0.5829\u001b[0m       0.6316        \u001b[35m0.6312\u001b[0m  0.2156\n",
      "     15        \u001b[36m0.5750\u001b[0m       \u001b[32m0.6579\u001b[0m        \u001b[35m0.6271\u001b[0m  0.2150\n",
      "     16        \u001b[36m0.5628\u001b[0m       0.6316        0.6512  0.2168\n",
      "     17        \u001b[36m0.5523\u001b[0m       0.5789        0.6512  0.2121\n",
      "     18        \u001b[36m0.5511\u001b[0m       0.5526        0.6554  0.2150\n",
      "     19        \u001b[36m0.5258\u001b[0m       0.6053        0.6404  0.2165\n",
      "     20        \u001b[36m0.5122\u001b[0m       0.5789        0.6381  0.2140\n",
      "     21        \u001b[36m0.5078\u001b[0m       0.5526        0.6357  0.2013\n",
      "     22        \u001b[36m0.4838\u001b[0m       0.5526        \u001b[35m0.6246\u001b[0m  0.2027\n",
      "     23        \u001b[36m0.4705\u001b[0m       0.6053        \u001b[35m0.6136\u001b[0m  0.2025\n",
      "     24        \u001b[36m0.4472\u001b[0m       \u001b[32m0.6842\u001b[0m        \u001b[35m0.5918\u001b[0m  0.2019\n",
      "     25        \u001b[36m0.4151\u001b[0m       \u001b[32m0.7105\u001b[0m        \u001b[35m0.5634\u001b[0m  0.2016\n",
      "     26        \u001b[36m0.4019\u001b[0m       0.6579        0.5776  0.2128\n",
      "     27        \u001b[36m0.3677\u001b[0m       0.7105        \u001b[35m0.5261\u001b[0m  0.2107\n",
      "     28        \u001b[36m0.3542\u001b[0m       \u001b[32m0.7632\u001b[0m        \u001b[35m0.5081\u001b[0m  0.2147\n",
      "     29        \u001b[36m0.3201\u001b[0m       0.7105        0.5416  0.2139\n",
      "     30        \u001b[36m0.3003\u001b[0m       0.7105        0.5402  0.2143\n",
      "     31        \u001b[36m0.2825\u001b[0m       0.7105        \u001b[35m0.5069\u001b[0m  0.2156\n",
      "     32        \u001b[36m0.2322\u001b[0m       0.7368        0.5537  0.2150\n",
      "     33        \u001b[36m0.2200\u001b[0m       0.6842        0.6431  0.2105\n",
      "     34        \u001b[36m0.1776\u001b[0m       0.6842        0.5998  0.2163\n",
      "     35        \u001b[36m0.1693\u001b[0m       0.7368        0.5705  0.2153\n",
      "     36        \u001b[36m0.1221\u001b[0m       0.6842        0.6047  0.2125\n",
      "     37        \u001b[36m0.1036\u001b[0m       0.6842        0.6412  0.2152\n",
      "     38        0.1303       0.7105        0.5748  0.2166\n",
      "     39        \u001b[36m0.0799\u001b[0m       0.6842        0.6189  0.2166\n",
      "     40        \u001b[36m0.0576\u001b[0m       0.6316        0.6415  0.2148\n"
     ]
    }
   ],
   "source": [
    "net.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5102040816326531"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, net.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
